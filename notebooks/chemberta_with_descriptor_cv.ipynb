{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kjxJq6pVrich",
    "outputId": "88e8ccb3-96e5-4573-dbef-f1fd7c5fd7fb"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N3QbRUnirsRg",
    "outputId": "ea85c44f-47ed-49fa-b3df-093030cee40e"
   },
   "outputs": [],
   "source": [
    "!pip install wandb\n",
    "!pip install transformers==4.0.0\n",
    "!pip install catalyst==20.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qXRj82KQtEkZ",
    "outputId": "f2685048-518f-4834-f870-0d129fc8e4c6"
   },
   "outputs": [],
   "source": [
    "!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zy-3KpEevDa9",
    "outputId": "4f3542c1-c752-4469-d634-1aa116a01861"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/lehgtrung/egfr-att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Ytw9q7mNrf2Q"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catalyst import dl\n",
    "from catalyst.utils import set_global_seed\n",
    "\n",
    "\n",
    "ORIGINAL_PAPER_PATH = Path(\"egfr-att\")\n",
    "import sys\n",
    "sys.path.append(ORIGINAL_PAPER_PATH.as_posix())\n",
    "\n",
    "\n",
    "from egfr.dataset import EGFRDataset, train_cross_validation_split\n",
    "\n",
    "\n",
    "\n",
    "DEVICE = torch.device('cuda')\n",
    "\n",
    "\n",
    "SEED = 21\n",
    "set_global_seed(SEED)\n",
    "\n",
    "\n",
    "DATA_PATH = ORIGINAL_PAPER_PATH / \"egfr/data/egfr_10_full_ft_pd_lines.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "QffNi5Rorf2S"
   },
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = 'chemberta-with-descriptor'\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "\n",
    "    pretrained_path: str = \"seyonec/PubChem10M_SMILES_BPE_450k\"\n",
    "    finetune_embeddings: bool = False\n",
    "    n_layers_to_finetune: int = 2\n",
    "\n",
    "    batch_size: int = 16\n",
    "    accumulation_steps: int = 8\n",
    "  \n",
    "    num_epochs: int = 100\n",
    "    patience: int = 10\n",
    "\n",
    "    scheduler: str = 'OneCycleLR'\n",
    "    max_lr: float = 0.00005\n",
    "    warmup_prop: float = 0.2\n",
    "\n",
    "    logdir: str = f'drive/MyDrive/logdir_{EXPERIMENT_NAME}'\n",
    "\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenizer_info(tokenizer):\n",
    "    for key, value in tokenizer.special_tokens_map.items():\n",
    "        print(f\"{key}:\", value, getattr(tokenizer, f\"{key}_id\"))\n",
    "\n",
    "\n",
    "def freeze_module(module: torch.nn.Module):\n",
    "    for p in module.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "\n",
    "def freeze_pretrained(model: 'RobertaModel', config: Config):\n",
    "    if not config.finetune_embeddings:\n",
    "        freeze_module(model.embeddings)\n",
    "\n",
    "    n_layers = len(model.encoder.layer)\n",
    "    layer_idx_to_stop = n_layers - config.n_layers_to_finetune\n",
    "    for i, layer in enumerate(model.encoder.layer):\n",
    "        if i == layer_idx_to_stop:\n",
    "            break\n",
    "        freeze_module(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceEGFRDataset(EGFRDataset):\n",
    "\n",
    "    def __init__(self, data, tokenizer):\n",
    "        super().__init__(data, infer=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.pad_token_id = tokenizer.pad_token_id\n",
    "        self.encode_smiles()\n",
    "\n",
    "        self.mord_ft = torch.FloatTensor(self.mord_ft)\n",
    "        self.non_mord_ft = torch.FloatTensor(self.non_mord_ft)\n",
    "        self.label = torch.LongTensor(self.label)\n",
    "\n",
    "    def encode_smiles(self):\n",
    "        self.smiles = [\n",
    "            torch.LongTensor(self.tokenizer.encode(s))\n",
    "            for s in self.smiles\n",
    "        ]\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        smiles, mord_ft, non_mord_ft, labels = zip(*batch)\n",
    "        smiles = pad_sequence(\n",
    "            smiles, batch_first=True, padding_value=self.pad_token_id\n",
    "        )\n",
    "        mord_ft = torch.stack(mord_ft)\n",
    "        non_mord_ft = torch.stack(non_mord_ft)\n",
    "        labels = torch.stack(labels)\n",
    "        return smiles, mord_ft, non_mord_ft, labels\n",
    "\n",
    "    def make_loader(self, *args, **kwargs):\n",
    "        return DataLoader(self, *args, collate_fn=self.collate_fn, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelWithDescriptor(nn.Module):\n",
    "\n",
    "    def __init__(self, transformer, dense_dim):\n",
    "        super().__init__()\n",
    "        self.transformer = transformer\n",
    "        self.dropout_prob = transformer.config.hidden_dropout_prob\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(dense_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(p=self.dropout_prob),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(p=self.dropout_prob),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(p=self.dropout_prob)\n",
    "        )\n",
    "        self.fc_out = nn.Linear(transformer.config.hidden_size + 64, 1)\n",
    "\n",
    "    def forward(self, smiles, descriptor):\n",
    "        pooler_out = self.transformer(input_ids=smiles).pooler_output\n",
    "        pooler_out = torch.nn.functional.dropout(pooler_out, p=self.dropout_prob)\n",
    "        dense_out = self.dense(descriptor)\n",
    "        return self.fc_out(torch.cat([pooler_out, dense_out], dim=-1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "6zc_z-m4rf2V"
   },
   "outputs": [],
   "source": [
    "def init_scheduler(\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    num_steps_per_epoch: int,\n",
    "    config: Config\n",
    "):\n",
    "\n",
    "    if config.scheduler == 'OneCycleLR':\n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr=config.max_lr,\n",
    "            epochs=config.num_epochs,\n",
    "            steps_per_epoch=num_steps_per_epoch,\n",
    "            pct_start=config.warmup_prop\n",
    "        )\n",
    "        return scheduler, 'batch'\n",
    "\n",
    "    return None, None\n",
    "\n",
    "\n",
    "class EgfrWithDescriptorRunner(dl.Runner):\n",
    "\n",
    "    def _handle_batch(self, batch):\n",
    "        smiles, mord, _, labels = batch\n",
    "        out = self.model(smiles, mord)\n",
    "        self.batch_metrics['loss'] = torch.nn.functional.binary_cross_entropy_with_logits(\n",
    "            out, labels.unsqueeze(-1).to(torch.float32)\n",
    "        )\n",
    "        self.input = {'targets': labels}\n",
    "        self.output = {'logits': out}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cI5FoiV3rf2S",
    "outputId": "b25be391-9b8f-4dbe-f605-c1d936eec6ce"
   },
   "outputs": [],
   "source": [
    "def experiment(train, valid, config, experiment_name, fold_idx):\n",
    "\n",
    "    pretrained_model = AutoModel.from_pretrained(config.pretrained_path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(config.pretrained_path)\n",
    "    PAD_TOKEN_ID = tokenizer.pad_token_id\n",
    "    freeze_pretrained(pretrained_model, config)\n",
    "\n",
    "    train_dataset = SequenceEGFRDataset(train, tokenizer)\n",
    "    valid_dataset = SequenceEGFRDataset(valid, tokenizer)\n",
    "\n",
    "    model = ModelWithDescriptor(pretrained_model, dense_dim=train_dataset.mord_ft.size(-1))\n",
    "    \n",
    "    loaders = {\n",
    "        'train': train_dataset.make_loader(batch_size=config.batch_size, shuffle=True),\n",
    "        'valid': valid_dataset.make_loader(batch_size=config.batch_size)\n",
    "    }\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "    callbacks = [\n",
    "        dl.OptimizerCallback(accumulation_steps=config.accumulation_steps),\n",
    "        dl.EarlyStoppingCallback(patience=config.patience),\n",
    "        dl.WandbLogger(\n",
    "            project='egfr-project',\n",
    "            entity='dimaorekhov',\n",
    "            group=f\"{EXPERIMENT_NAME}_CV\",\n",
    "            name=f\"{EXPERIMENT_NAME}_fold_{fold_idx}\",\n",
    "            config=config.__dict__\n",
    "        ),\n",
    "        dl.AUCCallback(activation='Sigmoid')\n",
    "    ]\n",
    "\n",
    "    scheduler, mode = init_scheduler(optimizer, len(loaders['train']), config)\n",
    "    if scheduler is not None:\n",
    "        callbacks.append(dl.SchedulerCallback(mode=mode))\n",
    "        \n",
    "    # be careful not to override log dir\n",
    "    Path(config.logdir).mkdir(exist_ok=True)\n",
    "    \n",
    "    runner = EgfrWithDescriptorRunner(device=DEVICE)\n",
    "    runner.train(\n",
    "        model=model,\n",
    "        loaders=loaders,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,        \n",
    "        num_epochs=config.num_epochs,\n",
    "        verbose=True,\n",
    "        logdir=config.logdir,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    \n",
    "    model.to(torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (train, valid) in enumerate(train_cross_validation_split(DATA_PATH.as_posix())):\n",
    "    experiment(train, valid, config, EXPERIMENT_NAME, i)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "chemberta-with-descriptor.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "160374a7921e49288410cfba8e16c0ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "29432d3d30ed450e9041c554c6e9b1c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a65d66dad22d4233bd84f538edd390e3",
       "IPY_MODEL_eefe9d0be8314f019cd5b1d10599d6f2"
      ],
      "layout": "IPY_MODEL_c6656d45837a446fb51f7244e5937f55"
     }
    },
    "3bf067250e0e4b97aa1ef3d67d8c4485": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9bd802ecb77b465980ed2a20cbe03f17": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a65d66dad22d4233bd84f538edd390e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fc8ecfd3ceb44b63b61ac0775656af7d",
      "placeholder": "​",
      "style": "IPY_MODEL_3bf067250e0e4b97aa1ef3d67d8c4485",
      "value": " 0.69MB of 0.69MB uploaded (0.00MB deduped)\r"
     }
    },
    "c6656d45837a446fb51f7244e5937f55": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eefe9d0be8314f019cd5b1d10599d6f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9bd802ecb77b465980ed2a20cbe03f17",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_160374a7921e49288410cfba8e16c0ca",
      "value": 1
     }
    },
    "fc8ecfd3ceb44b63b61ac0775656af7d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
