{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "chemberta-with-descriptor.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "29432d3d30ed450e9041c554c6e9b1c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c6656d45837a446fb51f7244e5937f55",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a65d66dad22d4233bd84f538edd390e3",
              "IPY_MODEL_eefe9d0be8314f019cd5b1d10599d6f2"
            ]
          }
        },
        "c6656d45837a446fb51f7244e5937f55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a65d66dad22d4233bd84f538edd390e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_3bf067250e0e4b97aa1ef3d67d8c4485",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.69MB of 0.69MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fc8ecfd3ceb44b63b61ac0775656af7d"
          }
        },
        "eefe9d0be8314f019cd5b1d10599d6f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_160374a7921e49288410cfba8e16c0ca",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9bd802ecb77b465980ed2a20cbe03f17"
          }
        },
        "3bf067250e0e4b97aa1ef3d67d8c4485": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fc8ecfd3ceb44b63b61ac0775656af7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "160374a7921e49288410cfba8e16c0ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9bd802ecb77b465980ed2a20cbe03f17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjxJq6pVrich",
        "outputId": "88e8ccb3-96e5-4573-dbef-f1fd7c5fd7fb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3QbRUnirsRg",
        "outputId": "ea85c44f-47ed-49fa-b3df-093030cee40e"
      },
      "source": [
        "!pip install wandb\n",
        "!pip install transformers==4.0.0\n",
        "!pip install catalyst==20.11"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.6/dist-packages (0.10.12)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.8.1)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.1.11)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.12.4)\n",
            "Requirement already satisfied: subprocess32>=3.5.3 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.5.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: configparser>=3.8.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.0.1)\n",
            "Requirement already satisfied: sentry-sdk>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.19.5)\n",
            "Requirement already satisfied: watchdog>=0.8.3 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.0.1)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.6/dist-packages (from GitPython>=1.0.0->wandb) (4.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.12.0->wandb) (50.3.2)\n",
            "Requirement already satisfied: smmap<4,>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: transformers==4.0.0 in /usr/local/lib/python3.6/dist-packages (4.0.0)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0) (0.9.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0) (0.0.43)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0) (1.18.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0) (20.7)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0) (0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0) (3.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.0.0) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.0.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.0.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.0.0) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==4.0.0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==4.0.0) (0.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==4.0.0) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==4.0.0) (2.4.7)\n",
            "Requirement already satisfied: catalyst==20.11 in /usr/local/lib/python3.6/dist-packages (20.11)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from catalyst==20.11) (5.5.0)\n",
            "Requirement already satisfied: tensorboard>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from catalyst==20.11) (2.3.0)\n",
            "Requirement already satisfied: tqdm>=4.33.0 in /usr/local/lib/python3.6/dist-packages (from catalyst==20.11) (4.41.1)\n",
            "Requirement already satisfied: plotly>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from catalyst==20.11) (4.4.1)\n",
            "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.6/dist-packages (from catalyst==20.11) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.6/dist-packages (from catalyst==20.11) (0.22.2.post1)\n",
            "Requirement already satisfied: deprecation in /usr/local/lib/python3.6/dist-packages (from catalyst==20.11) (2.1.0)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.6/dist-packages (from catalyst==20.11) (2.1)\n",
            "Requirement already satisfied: pandas>=0.22 in /usr/local/lib/python3.6/dist-packages (from catalyst==20.11) (1.1.5)\n",
            "Requirement already satisfied: GitPython>=3.1.1 in /usr/local/lib/python3.6/dist-packages (from catalyst==20.11) (3.1.11)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from catalyst==20.11) (20.7)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catalyst==20.11) (3.2.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from catalyst==20.11) (3.13)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from catalyst==20.11) (1.7.0+cu101)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst==20.11) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst==20.11) (50.3.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst==20.11) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst==20.11) (1.0.18)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst==20.11) (4.3.3)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst==20.11) (2.6.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst==20.11) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst==20.11) (4.4.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst==20.11) (3.3.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst==20.11) (0.4.2)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst==20.11) (3.12.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst==20.11) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst==20.11) (1.34.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst==20.11) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst==20.11) (1.17.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst==20.11) (1.7.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst==20.11) (0.36.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst==20.11) (2.23.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst==20.11) (0.10.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly>=4.1.0->catalyst==20.11) (1.3.3)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20->catalyst==20.11) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20->catalyst==20.11) (0.17.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22->catalyst==20.11) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22->catalyst==20.11) (2.8.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.6/dist-packages (from GitPython>=3.1.1->catalyst==20.11) (4.0.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->catalyst==20.11) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catalyst==20.11) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catalyst==20.11) (1.3.1)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->catalyst==20.11) (0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->catalyst==20.11) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->catalyst==20.11) (3.7.4.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->catalyst==20.11) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->catalyst==20.11) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->catalyst==20.11) (0.6.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard>=1.14.0->catalyst==20.11) (3.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14.0->catalyst==20.11) (1.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14.0->catalyst==20.11) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14.0->catalyst==20.11) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14.0->catalyst==20.11) (4.1.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14.0->catalyst==20.11) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14.0->catalyst==20.11) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14.0->catalyst==20.11) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14.0->catalyst==20.11) (2020.12.5)\n",
            "Requirement already satisfied: smmap<4,>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from gitdb<5,>=4.0.1->GitPython>=3.1.1->catalyst==20.11) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=1.14.0->catalyst==20.11) (3.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14.0->catalyst==20.11) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard>=1.14.0->catalyst==20.11) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXRj82KQtEkZ",
        "outputId": "f2685048-518f-4834-f870-0d129fc8e4c6"
      },
      "source": [
        "!wandb login"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdimaorekhov\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zy-3KpEevDa9",
        "outputId": "4f3542c1-c752-4469-d634-1aa116a01861"
      },
      "source": [
        "!git clone https://github.com/lehgtrung/egfr-att"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'egfr-att' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ytw9q7mNrf2Q"
      },
      "source": [
        "from pathlib import Path\n",
        "import json\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import pandas as pd\n",
        "from dataclasses import dataclass\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from sklearn.model_selection import train_test_split\n",
        "from catalyst import dl\n",
        "from catalyst.utils import set_global_seed\n",
        "\n",
        "\n",
        "ORIGINAL_PAPER_PATH = Path(\"egfr-att\")\n",
        "import sys\n",
        "sys.path.append(ORIGINAL_PAPER_PATH.as_posix())\n",
        "\n",
        "\n",
        "from egfr.dataset import EGFRDataset\n",
        "\n",
        "\n",
        "DEVICE = torch.device('cuda')\n",
        "\n",
        "\n",
        "SEED = 21\n",
        "set_global_seed(SEED)\n",
        "\n",
        "\n",
        "DATA_PATH = ORIGINAL_PAPER_PATH / \"egfr/data/egfr_10_full_ft_pd_lines.json\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QffNi5Rorf2S"
      },
      "source": [
        "EXPERIMENT_NAME = 'chemberta-with-descriptor'\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "\n",
        "    pretrained_path: str = \"seyonec/PubChem10M_SMILES_BPE_450k\"\n",
        "    finetune_embeddings: bool = False\n",
        "    n_layers_to_finetune: int = 2\n",
        "\n",
        "    batch_size: int = 16\n",
        "    accumulation_steps: int = 8\n",
        "  \n",
        "    num_epochs: int = 100\n",
        "    patience: int = 10\n",
        "\n",
        "    scheduler: str = 'OneCycleLR'\n",
        "    max_lr: float = 0.00005\n",
        "    warmup_prop: float = 0.2\n",
        "\n",
        "    logdir: str = f'drive/MyDrive/logdir_{EXPERIMENT_NAME}'\n",
        "\n",
        "\n",
        "config = Config()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cI5FoiV3rf2S",
        "outputId": "b25be391-9b8f-4dbe-f605-c1d936eec6ce"
      },
      "source": [
        "pretrained_model = AutoModel.from_pretrained(config.pretrained_path)\n",
        "tokenizer = AutoTokenizer.from_pretrained(config.pretrained_path)\n",
        "\n",
        "\n",
        "def get_tokenizer_info(tokenizer):\n",
        "    for key, value in tokenizer.special_tokens_map.items():\n",
        "        print(f\"{key}:\", value, getattr(tokenizer, f\"{key}_id\"))\n",
        "\n",
        "get_tokenizer_info(tokenizer)\n",
        "\n",
        "\n",
        "PAD_TOKEN_ID = tokenizer.pad_token_id"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bos_token: <s> 0\n",
            "eos_token: </s> 2\n",
            "unk_token: <unk> 3\n",
            "sep_token: </s> 2\n",
            "pad_token: <pad> 1\n",
            "cls_token: <s> 0\n",
            "mask_token: <mask> 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9NjD1UWrf2T"
      },
      "source": [
        "def freeze_module(module: torch.nn.Module):\n",
        "    for p in module.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "\n",
        "def freeze_pretrained(model: 'RobertaModel', config: Config):\n",
        "    if not config.finetune_embeddings:\n",
        "        freeze_module(model.embeddings)\n",
        "\n",
        "    n_layers = len(model.encoder.layer)\n",
        "    layer_idx_to_stop = n_layers - config.n_layers_to_finetune\n",
        "    for i, layer in enumerate(model.encoder.layer):\n",
        "        if i == layer_idx_to_stop:\n",
        "            break\n",
        "        freeze_module(layer)\n",
        "\n",
        "\n",
        "freeze_pretrained(pretrained_model, config)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISaOSCfKrf2T"
      },
      "source": [
        "class SequenceEGFRDataset(EGFRDataset):\n",
        "\n",
        "    def __init__(self, data, tokenizer):\n",
        "        super().__init__(data, infer=True)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.pad_token_id = tokenizer.pad_token_id\n",
        "        self.encode_smiles()\n",
        "\n",
        "        self.mord_ft = torch.FloatTensor(self.mord_ft)\n",
        "        self.non_mord_ft = torch.FloatTensor(self.non_mord_ft)\n",
        "        self.label = torch.LongTensor(self.label)\n",
        "\n",
        "    def encode_smiles(self):\n",
        "        self.smiles = [\n",
        "            torch.LongTensor(self.tokenizer.encode(s))\n",
        "            for s in self.smiles\n",
        "        ]\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "        smiles, mord_ft, non_mord_ft, labels = zip(*batch)\n",
        "        smiles = pad_sequence(\n",
        "            smiles, batch_first=True, padding_value=self.pad_token_id\n",
        "        )\n",
        "        mord_ft = torch.stack(mord_ft)\n",
        "        non_mord_ft = torch.stack(non_mord_ft)\n",
        "        labels = torch.stack(labels)\n",
        "        return smiles, mord_ft, non_mord_ft, labels\n",
        "\n",
        "    def make_loader(self, *args, **kwargs):\n",
        "        return DataLoader(self, *args, collate_fn=self.collate_fn, **kwargs)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjJpoUBTrf2U"
      },
      "source": [
        "train, valid = train_test_split(\n",
        "    pd.read_json(DATA_PATH, lines=True), test_size=0.2, random_state=42 #  42 hard code is from original paper code \n",
        ")\n",
        "\n",
        "\n",
        "train_dataset = SequenceEGFRDataset(train, tokenizer)\n",
        "valid_dataset = SequenceEGFRDataset(valid, tokenizer)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYl2iWlKrf2U",
        "outputId": "df6fbec7-6fc0-4483-d286-c19525749e0a"
      },
      "source": [
        "print('Max train smiles length:', max(len(s) for s in train_dataset.smiles))\n",
        "print('Max valid smiles length:', max(len(s) for s in valid_dataset.smiles))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max train smiles length: 100\n",
            "Max valid smiles length: 93\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76btpzRQBph7"
      },
      "source": [
        "class ModelWithDescriptor(nn.Module):\n",
        "\n",
        "    def __init__(self, transformer, dense_dim):\n",
        "      super().__init__()\n",
        "      self.transformer = transformer\n",
        "      self.dropout_prob = transformer.config.hidden_dropout_prob\n",
        "      self.dense = nn.Sequential(\n",
        "          nn.Linear(dense_dim, 512),\n",
        "          nn.ReLU(),\n",
        "          nn.BatchNorm1d(512),\n",
        "          nn.Dropout(p=self.dropout_prob),\n",
        "          nn.Linear(512, 128),\n",
        "          nn.ReLU(),\n",
        "          nn.BatchNorm1d(128),\n",
        "          nn.Dropout(p=self.dropout_prob),\n",
        "          nn.Linear(128, 64),\n",
        "          nn.ReLU(),\n",
        "          nn.BatchNorm1d(64),\n",
        "          nn.Dropout(p=self.dropout_prob)\n",
        "      )\n",
        "      self.fc_out = nn.Linear(transformer.config.hidden_size + 64, 1)\n",
        "\n",
        "    def forward(self, smiles, descriptor):\n",
        "        pooler_out = self.transformer(input_ids=smiles).pooler_output\n",
        "        pooler_out = torch.nn.functional.dropout(pooler_out, p=self.dropout_prob)\n",
        "        dense_out = self.dense(descriptor)\n",
        "        return self.fc_out(torch.cat([pooler_out, dense_out], dim=-1))\n",
        "\n",
        "\n",
        "model = ModelWithDescriptor(pretrained_model, dense_dim=train_dataset.mord_ft.size(-1))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IP5odF2orf2U"
      },
      "source": [
        "loaders = {\n",
        "    'train': train_dataset.make_loader(batch_size=config.batch_size, shuffle=True),\n",
        "    'valid': valid_dataset.make_loader(batch_size=config.batch_size)\n",
        "}"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zc_z-m4rf2V"
      },
      "source": [
        "def init_scheduler(\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    num_steps_per_epoch: int,\n",
        "    config: Config\n",
        "):\n",
        "\n",
        "    if config.scheduler == 'OneCycleLR':\n",
        "        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "            optimizer,\n",
        "            max_lr=config.max_lr,\n",
        "            epochs=config.num_epochs,\n",
        "            steps_per_epoch=num_steps_per_epoch,\n",
        "            pct_start=config.warmup_prop\n",
        "        )\n",
        "        return scheduler, 'batch'\n",
        "\n",
        "    return None, None\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2WliPf5rf2V"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "callbacks = [\n",
        "    dl.OptimizerCallback(accumulation_steps=config.accumulation_steps),\n",
        "    dl.EarlyStoppingCallback(patience=config.patience),\n",
        "    dl.WandbLogger(\n",
        "        project='egfr-project',\n",
        "        entity='dimaorekhov',\n",
        "        group='chemberta-with-descriptor',\n",
        "        name=EXPERIMENT_NAME,\n",
        "        config=config.__dict__\n",
        "    ),\n",
        "    dl.AUCCallback()\n",
        "]\n",
        "\n",
        "scheduler, mode = init_scheduler(optimizer, len(loaders['train']), config)\n",
        "if scheduler is not None:\n",
        "    callbacks.append(dl.SchedulerCallback(mode=mode))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0jiMB3Orf2V"
      },
      "source": [
        "class EgfrWithDescriptorRunner(dl.Runner):\n",
        "\n",
        "    def _handle_batch(self, batch):\n",
        "        smiles, mord, _, labels = batch\n",
        "        out = self.model(smiles, mord)\n",
        "        self.batch_metrics['loss'] = torch.nn.functional.binary_cross_entropy_with_logits(\n",
        "            out, labels.unsqueeze(-1).to(torch.float32)\n",
        "        )\n",
        "        self.input = {'targets': labels}\n",
        "        self.output = {'logits': out}\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXP1Kqowrf2V"
      },
      "source": [
        "# be careful not to override log dir\n",
        "Path(config.logdir).mkdir(exist_ok=True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "29432d3d30ed450e9041c554c6e9b1c5",
            "c6656d45837a446fb51f7244e5937f55",
            "a65d66dad22d4233bd84f538edd390e3",
            "eefe9d0be8314f019cd5b1d10599d6f2",
            "3bf067250e0e4b97aa1ef3d67d8c4485",
            "fc8ecfd3ceb44b63b61ac0775656af7d",
            "160374a7921e49288410cfba8e16c0ca",
            "9bd802ecb77b465980ed2a20cbe03f17"
          ]
        },
        "id": "Q85o-Y3urf2W",
        "outputId": "4c719cab-e1a4-4a1b-d8f8-4ead57414169"
      },
      "source": [
        "runner = EgfrWithDescriptorRunner(device=DEVICE)\n",
        "runner.train(\n",
        "    model=model,\n",
        "    loaders=loaders,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,        \n",
        "    num_epochs=config.num_epochs,\n",
        "    verbose=True,\n",
        "    logdir=config.logdir,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdimaorekhov\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.12<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">chemberta-with-descriptor</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/dimaorekhov/egfr-project\" target=\"_blank\">https://wandb.ai/dimaorekhov/egfr-project</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/dimaorekhov/egfr-project/runs/2kue2ih0\" target=\"_blank\">https://wandb.ai/dimaorekhov/egfr-project/runs/2kue2ih0</a><br/>\n",
              "                Run data is saved locally in <code>drive/MyDrive/logdir_chemberta-with-descriptor/wandb/run-20201211_233320-2kue2ih0</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "1/100 * Epoch (train):   1% 2/175 [00:00<00:20,  8.59it/s, loss=0.651, lr=2.000e-06, momentum=0.950]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning:\n",
            "\n",
            "Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:1241: UserWarning:\n",
            "\n",
            "To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1/100 * Epoch (train): 100% 175/175 [00:08<00:00, 19.92it/s, loss=0.441, lr=2.296e-06, momentum=0.949]\n",
            "1/100 * Epoch (valid): 100% 44/44 [00:01<00:00, 34.08it/s, loss=0.471]\n",
            "[2020-12-11 23:33:32,030] \n",
            "1/100 * Epoch 1 (_base): lr=2.296e-06 | momentum=0.9494\n",
            "1/100 * Epoch 1 (train): auc/class_00=0.5024 | auc/mean=0.5024 | loss=0.5773 | lr=2.099e-06 | momentum=0.9498\n",
            "1/100 * Epoch 1 (valid): auc/class_00=0.5019 | auc/mean=0.5019 | loss=0.5185\n",
            "2/100 * Epoch (train): 100% 175/175 [00:08<00:00, 19.54it/s, loss=0.363, lr=3.175e-06, momentum=0.948]\n",
            "2/100 * Epoch (valid): 100% 44/44 [00:01<00:00, 33.50it/s, loss=0.371]\n",
            "[2020-12-11 23:34:11,769] \n",
            "2/100 * Epoch 2 (_base): lr=3.175e-06 | momentum=0.9476\n",
            "2/100 * Epoch 2 (train): auc/class_00=0.5277 | auc/mean=0.5277 | loss=0.4740 | lr=2.689e-06 | momentum=0.9486\n",
            "2/100 * Epoch 2 (valid): auc/class_00=0.5310 | auc/mean=0.5310 | loss=0.4344\n",
            "3/100 * Epoch (train): 100% 175/175 [00:11<00:00, 15.90it/s, loss=0.357, lr=4.617e-06, momentum=0.945]\n",
            "3/100 * Epoch (valid): 100% 44/44 [00:01<00:00, 32.70it/s, loss=0.327]\n",
            "[2020-12-11 23:35:14,584] \n",
            "3/100 * Epoch 3 (_base): lr=4.617e-06 | momentum=0.9445\n",
            "3/100 * Epoch 3 (train): auc/class_00=0.5678 | auc/mean=0.5678 | loss=0.4208 | lr=3.853e-06 | momentum=0.9461\n",
            "3/100 * Epoch 3 (valid): auc/class_00=0.5984 | auc/mean=0.5984 | loss=0.4011\n",
            "4/100 * Epoch (train): 100% 175/175 [00:09<00:00, 19.35it/s, loss=0.338, lr=6.586e-06, momentum=0.940]\n",
            "4/100 * Epoch (valid): 100% 44/44 [00:01<00:00, 32.59it/s, loss=0.305]\n",
            "[2020-12-11 23:36:15,206] \n",
            "4/100 * Epoch 4 (_base): lr=6.586e-06 | momentum=0.9404\n",
            "4/100 * Epoch 4 (train): auc/class_00=0.6548 | auc/mean=0.6548 | loss=0.4018 | lr=5.563e-06 | momentum=0.9426\n",
            "4/100 * Epoch 4 (valid): auc/class_00=0.6857 | auc/mean=0.6857 | loss=0.3873\n",
            "5/100 * Epoch (train): 100% 175/175 [00:09<00:00, 19.03it/s, loss=0.293, lr=9.033e-06, momentum=0.935]\n",
            "5/100 * Epoch (valid): 100% 44/44 [00:01<00:00, 31.87it/s, loss=0.293]\n",
            "[2020-12-11 23:37:14,715] \n",
            "5/100 * Epoch 5 (_base): lr=9.033e-06 | momentum=0.9353\n",
            "5/100 * Epoch 5 (train): auc/class_00=0.7472 | auc/mean=0.7472 | loss=0.3832 | lr=7.776e-06 | momentum=0.9380\n",
            "5/100 * Epoch 5 (valid): auc/class_00=0.7728 | auc/mean=0.7728 | loss=0.3643\n",
            "6/100 * Epoch (train): 100% 175/175 [00:09<00:00, 19.28it/s, loss=0.373, lr=1.190e-05, momentum=0.929]\n",
            "6/100 * Epoch (valid): 100% 44/44 [00:01<00:00, 31.73it/s, loss=0.254]\n",
            "[2020-12-11 23:38:16,465] \n",
            "6/100 * Epoch 6 (_base): lr=1.190e-05 | momentum=0.9294\n",
            "6/100 * Epoch 6 (train): auc/class_00=0.8308 | auc/mean=0.8308 | loss=0.3536 | lr=1.044e-05 | momentum=0.9324\n",
            "6/100 * Epoch 6 (valid): auc/class_00=0.8209 | auc/mean=0.8209 | loss=0.3407\n",
            "7/100 * Epoch (train): 100% 175/175 [00:09<00:00, 19.05it/s, loss=0.243, lr=1.511e-05, momentum=0.923]\n",
            "7/100 * Epoch (valid): 100% 44/44 [00:01<00:00, 31.13it/s, loss=0.190]\n",
            "[2020-12-11 23:39:15,665] \n",
            "7/100 * Epoch 7 (_base): lr=1.511e-05 | momentum=0.9227\n",
            "7/100 * Epoch 7 (train): auc/class_00=0.8659 | auc/mean=0.8659 | loss=0.3215 | lr=1.348e-05 | momentum=0.9261\n",
            "7/100 * Epoch 7 (valid): auc/class_00=0.8581 | auc/mean=0.8581 | loss=0.3103\n",
            "8/100 * Epoch (train): 100% 175/175 [00:09<00:00, 18.97it/s, loss=0.403, lr=1.859e-05, momentum=0.915]\n",
            "8/100 * Epoch (valid): 100% 44/44 [00:01<00:00, 31.86it/s, loss=0.152]\n",
            "[2020-12-11 23:40:12,969] \n",
            "8/100 * Epoch 8 (_base): lr=1.859e-05 | momentum=0.9154\n",
            "8/100 * Epoch 8 (train): auc/class_00=0.8820 | auc/mean=0.8820 | loss=0.2886 | lr=1.684e-05 | momentum=0.9191\n",
            "8/100 * Epoch 8 (valid): auc/class_00=0.8862 | auc/mean=0.8862 | loss=0.2788\n",
            "9/100 * Epoch (train): 100% 175/175 [00:09<00:00, 18.83it/s, loss=0.278, lr=2.226e-05, momentum=0.908]\n",
            "9/100 * Epoch (valid): 100% 44/44 [00:01<00:00, 32.52it/s, loss=0.114]\n",
            "[2020-12-11 23:41:13,135] \n",
            "9/100 * Epoch 9 (_base): lr=2.226e-05 | momentum=0.9078\n",
            "9/100 * Epoch 9 (train): auc/class_00=0.9146 | auc/mean=0.9146 | loss=0.2503 | lr=2.042e-05 | momentum=0.9116\n",
            "9/100 * Epoch 9 (valid): auc/class_00=0.9110 | auc/mean=0.9110 | loss=0.2510\n",
            "10/100 * Epoch (train): 100% 175/175 [00:09<00:00, 18.93it/s, loss=0.167, lr=2.601e-05, momentum=0.900]\n",
            "10/100 * Epoch (valid): 100% 44/44 [00:01<00:00, 32.01it/s, loss=0.071]\n",
            "[2020-12-11 23:42:15,285] \n",
            "10/100 * Epoch 10 (_base): lr=2.601e-05 | momentum=0.9000\n",
            "10/100 * Epoch 10 (train): auc/class_00=0.9413 | auc/mean=0.9413 | loss=0.2110 | lr=2.414e-05 | momentum=0.9039\n",
            "10/100 * Epoch 10 (valid): auc/class_00=0.9277 | auc/mean=0.9277 | loss=0.2585\n",
            "11/100 * Epoch (train): 100% 175/175 [00:09<00:00, 18.71it/s, loss=0.027, lr=2.977e-05, momentum=0.892]\n",
            "11/100 * Epoch (valid): 100% 44/44 [00:01<00:00, 31.77it/s, loss=0.069]\n",
            "[2020-12-11 23:42:56,865] \n",
            "11/100 * Epoch 11 (_base): lr=2.977e-05 | momentum=0.8922\n",
            "11/100 * Epoch 11 (train): auc/class_00=0.9532 | auc/mean=0.9532 | loss=0.1893 | lr=2.790e-05 | momentum=0.8960\n",
            "11/100 * Epoch 11 (valid): auc/class_00=0.9360 | auc/mean=0.9360 | loss=0.2235\n",
            "12/100 * Epoch (train): 100% 175/175 [00:09<00:00, 18.33it/s, loss=0.017, lr=3.343e-05, momentum=0.885]\n",
            "12/100 * Epoch (valid): 100% 44/44 [00:01<00:00, 30.88it/s, loss=0.029]\n",
            "[2020-12-11 23:43:56,696] \n",
            "12/100 * Epoch 12 (_base): lr=3.343e-05 | momentum=0.8845\n",
            "12/100 * Epoch 12 (train): auc/class_00=0.9630 | auc/mean=0.9630 | loss=0.1710 | lr=3.161e-05 | momentum=0.8883\n",
            "12/100 * Epoch 12 (valid): auc/class_00=0.9381 | auc/mean=0.9381 | loss=0.2367\n",
            "13/100 * Epoch (train): 100% 175/175 [00:09<00:00, 17.99it/s, loss=0.199, lr=3.691e-05, momentum=0.877]\n",
            "13/100 * Epoch (valid): 100% 44/44 [00:01<00:00, 30.34it/s, loss=0.057]\n",
            "[2020-12-11 23:44:35,916] \n",
            "13/100 * Epoch 13 (_base): lr=3.691e-05 | momentum=0.8773\n",
            "13/100 * Epoch 13 (train): auc/class_00=0.9670 | auc/mean=0.9670 | loss=0.1594 | lr=3.519e-05 | momentum=0.8808\n",
            "13/100 * Epoch 13 (valid): auc/class_00=0.9430 | auc/mean=0.9430 | loss=0.2171\n",
            "14/100 * Epoch (train): 100% 175/175 [00:09<00:00, 17.90it/s, loss=0.306, lr=4.012e-05, momentum=0.871]\n",
            "14/100 * Epoch (valid): 100% 44/44 [00:01<00:00, 30.26it/s, loss=0.023]\n",
            "[2020-12-11 23:45:36,163] \n",
            "14/100 * Epoch 14 (_base): lr=4.012e-05 | momentum=0.8706\n",
            "14/100 * Epoch 14 (train): auc/class_00=0.9745 | auc/mean=0.9745 | loss=0.1424 | lr=3.854e-05 | momentum=0.8739\n",
            "14/100 * Epoch 14 (valid): auc/class_00=0.9401 | auc/mean=0.9401 | loss=0.2233\n",
            "15/100 * Epoch (train): 100% 175/175 [00:09<00:00, 18.00it/s, loss=0.189, lr=4.298e-05, momentum=0.865]\n",
            "15/100 * Epoch (valid): 100% 44/44 [00:01<00:00, 30.74it/s, loss=0.020]\n",
            "[2020-12-11 23:46:13,838] \n",
            "15/100 * Epoch 15 (_base): lr=4.298e-05 | momentum=0.8646\n",
            "15/100 * Epoch 15 (train): auc/class_00=0.9799 | auc/mean=0.9799 | loss=0.1264 | lr=4.159e-05 | momentum=0.8675\n",
            "15/100 * Epoch 15 (valid): auc/class_00=0.9402 | auc/mean=0.9402 | loss=0.2307\n",
            "16/100 * Epoch (train): 100% 175/175 [00:09<00:00, 17.57it/s, loss=0.037, lr=4.543e-05, momentum=0.860]\n",
            "16/100 * Epoch (valid): 100% 44/44 [00:01<00:00, 29.81it/s, loss=0.046]\n",
            "[2020-12-11 23:46:56,987] \n",
            "16/100 * Epoch 16 (_base): lr=4.543e-05 | momentum=0.8595\n",
            "16/100 * Epoch 16 (train): auc/class_00=0.9835 | auc/mean=0.9835 | loss=0.1142 | lr=4.425e-05 | momentum=0.8620\n",
            "16/100 * Epoch 16 (valid): auc/class_00=0.9401 | auc/mean=0.9401 | loss=0.2466\n",
            "17/100 * Epoch (train): 100% 175/175 [00:09<00:00, 18.26it/s, loss=0.028, lr=4.739e-05, momentum=0.855]\n",
            "17/100 * Epoch (valid): 100% 44/44 [00:01<00:00, 30.74it/s, loss=0.022]\n",
            "[2020-12-11 23:47:33,560] \n",
            "17/100 * Epoch 17 (_base): lr=4.739e-05 | momentum=0.8554\n",
            "17/100 * Epoch 17 (train): auc/class_00=0.9872 | auc/mean=0.9872 | loss=0.1028 | lr=4.645e-05 | momentum=0.8574\n",
            "17/100 * Epoch 17 (valid): auc/class_00=0.9408 | auc/mean=0.9408 | loss=0.2496\n",
            "18/100 * Epoch (train): 100% 175/175 [00:09<00:00, 17.76it/s, loss=0.168, lr=4.883e-05, momentum=0.852]\n",
            "18/100 * Epoch (valid): 100% 44/44 [00:01<00:00, 29.93it/s, loss=0.006]\n",
            "[2020-12-11 23:48:16,222] \n",
            "18/100 * Epoch 18 (_base): lr=4.883e-05 | momentum=0.8524\n",
            "18/100 * Epoch 18 (train): auc/class_00=0.9881 | auc/mean=0.9881 | loss=0.0975 | lr=4.816e-05 | momentum=0.8538\n",
            "18/100 * Epoch 18 (valid): auc/class_00=0.9427 | auc/mean=0.9427 | loss=0.2673\n",
            "19/100 * Epoch (train): 100% 175/175 [00:09<00:00, 18.02it/s, loss=0.036, lr=4.971e-05, momentum=0.851]\n",
            "19/100 * Epoch (valid): 100% 44/44 [00:01<00:00, 30.57it/s, loss=0.005]\n",
            "[2020-12-11 23:48:57,009] \n",
            "19/100 * Epoch 19 (_base): lr=4.971e-05 | momentum=0.8506\n",
            "19/100 * Epoch 19 (train): auc/class_00=0.9903 | auc/mean=0.9903 | loss=0.0878 | lr=4.932e-05 | momentum=0.8514\n",
            "19/100 * Epoch 19 (valid): auc/class_00=0.9393 | auc/mean=0.9393 | loss=0.2805\n",
            "20/100 * Epoch (train): 100% 175/175 [00:09<00:00, 17.73it/s, loss=0.176, lr=5.000e-05, momentum=0.850]\n",
            "20/100 * Epoch (valid): 100% 44/44 [00:01<00:00, 29.67it/s, loss=0.008]\n",
            "[2020-12-11 23:49:34,072] \n",
            "20/100 * Epoch 20 (_base): lr=5.000e-05 | momentum=0.8500\n",
            "20/100 * Epoch 20 (train): auc/class_00=0.9915 | auc/mean=0.9915 | loss=0.0821 | lr=4.990e-05 | momentum=0.8502\n",
            "20/100 * Epoch 20 (valid): auc/class_00=0.9422 | auc/mean=0.9422 | loss=0.2773\n",
            "21/100 * Epoch (train): 100% 175/175 [00:09<00:00, 18.22it/s, loss=0.002, lr=4.998e-05, momentum=0.850]\n",
            "21/100 * Epoch (valid): 100% 44/44 [00:01<00:00, 31.07it/s, loss=0.006]\n",
            "[2020-12-11 23:50:17,431] \n",
            "21/100 * Epoch 21 (_base): lr=4.998e-05 | momentum=0.8500\n",
            "21/100 * Epoch 21 (train): auc/class_00=0.9935 | auc/mean=0.9935 | loss=0.0731 | lr=4.999e-05 | momentum=0.8500\n",
            "21/100 * Epoch 21 (valid): auc/class_00=0.9402 | auc/mean=0.9402 | loss=0.2876\n",
            "22/100 * Epoch (train): 100% 175/175 [00:09<00:00, 17.94it/s, loss=0.029, lr=4.992e-05, momentum=0.850]\n",
            "22/100 * Epoch (valid): 100% 44/44 [00:01<00:00, 30.54it/s, loss=0.004]\n",
            "[2020-12-11 23:50:56,783] \n",
            "22/100 * Epoch 22 (_base): lr=4.992e-05 | momentum=0.8502\n",
            "22/100 * Epoch 22 (train): auc/class_00=0.9949 | auc/mean=0.9949 | loss=0.0654 | lr=4.995e-05 | momentum=0.8501\n",
            "22/100 * Epoch 22 (valid): auc/class_00=0.9416 | auc/mean=0.9416 | loss=0.2957\n",
            "23/100 * Epoch (train): 100% 175/175 [00:09<00:00, 18.20it/s, loss=0.004, lr=4.983e-05, momentum=0.850]\n",
            "23/100 * Epoch (valid): 100% 44/44 [00:01<00:00, 30.30it/s, loss=0.003]\n",
            "[2020-12-11 23:51:37,454] \n",
            "23/100 * Epoch 23 (_base): lr=4.983e-05 | momentum=0.8503\n",
            "23/100 * Epoch 23 (train): auc/class_00=0.9954 | auc/mean=0.9954 | loss=0.0623 | lr=4.988e-05 | momentum=0.8502\n",
            "23/100 * Epoch 23 (valid): auc/class_00=0.9381 | auc/mean=0.9381 | loss=0.3189\n",
            "Early stop at 23 epoch\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 1128<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "29432d3d30ed450e9041c554c6e9b1c5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.02MB of 0.02MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>drive/MyDrive/logdir_chemberta-with-descriptor/wandb/run-20201211_233320-2kue2ih0/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>drive/MyDrive/logdir_chemberta-with-descriptor/wandb/run-20201211_233320-2kue2ih0/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>auc/class_00/train</td><td>0.99543</td></tr><tr><td>auc/mean/train</td><td>0.99543</td></tr><tr><td>loss/train</td><td>0.06226</td></tr><tr><td>lr/train</td><td>5e-05</td></tr><tr><td>momentum/train</td><td>0.85025</td></tr><tr><td>auc/class_00/valid</td><td>0.9381</td></tr><tr><td>auc/mean/valid</td><td>0.9381</td></tr><tr><td>loss/valid</td><td>0.31887</td></tr><tr><td>lr/_base</td><td>5e-05</td></tr><tr><td>momentum/_base</td><td>0.85035</td></tr><tr><td>_step</td><td>23</td></tr><tr><td>_runtime</td><td>1097</td></tr><tr><td>_timestamp</td><td>1607730697</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>auc/class_00/train</td><td>▁▁▂▃▄▆▆▆▇▇▇████████████</td></tr><tr><td>auc/mean/train</td><td>▁▁▂▃▄▆▆▆▇▇▇████████████</td></tr><tr><td>loss/train</td><td>█▇▆▆▅▅▅▄▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>lr/train</td><td>▁▁▁▂▂▂▃▃▄▄▅▅▆▆▇▇▇██████</td></tr><tr><td>momentum/train</td><td>███▇▇▇▆▆▅▅▄▄▃▃▂▂▂▁▁▁▁▁▁</td></tr><tr><td>auc/class_00/valid</td><td>▁▁▃▄▅▆▇▇▇██████████████</td></tr><tr><td>auc/mean/valid</td><td>▁▁▃▄▅▆▇▇▇██████████████</td></tr><tr><td>loss/valid</td><td>█▆▅▅▄▄▃▂▂▂▁▁▁▁▁▂▂▂▂▂▃▃▃</td></tr><tr><td>lr/_base</td><td>▁▁▁▂▂▂▃▃▄▄▅▆▆▇▇▇███████</td></tr><tr><td>momentum/_base</td><td>███▇▇▇▆▆▅▅▄▃▃▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>_step</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>_runtime</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▆▆▇▇▇▇██</td></tr><tr><td>_timestamp</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▆▆▇▇▇▇██</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">chemberta-with-descriptor</strong>: <a href=\"https://wandb.ai/dimaorekhov/egfr-project/runs/2kue2ih0\" target=\"_blank\">https://wandb.ai/dimaorekhov/egfr-project/runs/2kue2ih0</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Top best models:\n",
            "drive/MyDrive/logdir_chemberta-with-descriptor/checkpoints/train.13.pth\t0.2171\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6Qc8WSTv5mt"
      },
      "source": [
        ""
      ],
      "execution_count": 18,
      "outputs": []
    }
  ]
}