{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kjxJq6pVrich",
    "outputId": "b54e4750-ff30-4163-c21b-67798929efb3"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N3QbRUnirsRg",
    "outputId": "5c011c5b-f32c-41fd-9f7b-fd2144a2e8a0"
   },
   "outputs": [],
   "source": [
    "!pip install wandb\n",
    "!pip install transformers==4.0.0\n",
    "!pip install catalyst==20.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qXRj82KQtEkZ",
    "outputId": "c6350dca-6754-444e-cb7e-10d5d63918d1"
   },
   "outputs": [],
   "source": [
    "!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zy-3KpEevDa9",
    "outputId": "cf3810be-907f-44e5-e0b2-4560b687d683"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/lehgtrung/egfr-att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Ytw9q7mNrf2Q"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "from transformers import AutoTokenizer, RobertaForSequenceClassification, RobertaConfig\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catalyst import dl\n",
    "from catalyst.utils import set_global_seed\n",
    "\n",
    "\n",
    "ORIGINAL_PAPER_PATH = Path(\"egfr-att\")\n",
    "import sys\n",
    "sys.path.append(ORIGINAL_PAPER_PATH.as_posix())\n",
    "\n",
    "\n",
    "from egfr.dataset import EGFRDataset, train_cross_validation_split\n",
    "\n",
    "\n",
    "DEVICE = torch.device('cuda')\n",
    "\n",
    "\n",
    "SEED = 21\n",
    "set_global_seed(SEED)\n",
    "\n",
    "\n",
    "DATA_PATH = ORIGINAL_PAPER_PATH / \"egfr/data/egfr_10_full_ft_pd_lines.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QffNi5Rorf2S"
   },
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = 'transformer-no-descriptor'\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "\n",
    "    tokenizer_path: str = \"seyonec/PubChem10M_SMILES_BPE_450k\"\n",
    "\n",
    "    hidden_size: int = 768\n",
    "    num_hidden_layers: int = 2\n",
    "    num_attention_heads: int = 12\n",
    "    intermediate_size: int = 3072\n",
    "    hidden_dropout_prob: float = 0.1\n",
    "    attention_probs_dropout_prob: float = 0.1\n",
    "\n",
    "    batch_size: int = 16\n",
    "    accumulation_steps: int = 8\n",
    "  \n",
    "    num_epochs: int = 100\n",
    "    patience: int = 10\n",
    "\n",
    "    scheduler: str = 'OneCycleLR'\n",
    "    max_lr: float = 0.0005\n",
    "    warmup_prop: float = 0.2\n",
    "\n",
    "    logdir: str = f'drive/MyDrive/logdir_{EXPERIMENT_NAME}'\n",
    "\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceEGFRDataset(EGFRDataset):\n",
    "\n",
    "    def __init__(self, data, tokenizer):\n",
    "        super().__init__(data, infer=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.pad_token_id = tokenizer.pad_token_id\n",
    "        self.encode_smiles()\n",
    "\n",
    "        self.mord_ft = torch.FloatTensor(self.mord_ft)\n",
    "        self.non_mord_ft = torch.FloatTensor(self.non_mord_ft)\n",
    "        self.label = torch.LongTensor(self.label)\n",
    "\n",
    "    def encode_smiles(self):\n",
    "        self.smiles = [\n",
    "            torch.LongTensor(self.tokenizer.encode(s))\n",
    "            for s in self.smiles\n",
    "        ]\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        smiles, mord_ft, non_mord_ft, labels = zip(*batch)\n",
    "        smiles = pad_sequence(\n",
    "            smiles, batch_first=True, padding_value=self.pad_token_id\n",
    "        )\n",
    "        mord_ft = torch.stack(mord_ft)\n",
    "        non_mord_ft = torch.stack(non_mord_ft)\n",
    "        labels = torch.stack(labels)\n",
    "        return smiles, mord_ft, non_mord_ft, labels\n",
    "\n",
    "    def make_loader(self, *args, **kwargs):\n",
    "        return DataLoader(self, *args, collate_fn=self.collate_fn, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_scheduler(\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    num_steps_per_epoch: int,\n",
    "    config: Config\n",
    "):\n",
    "\n",
    "    if config.scheduler == 'OneCycleLR':\n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr=config.max_lr,\n",
    "            epochs=config.num_epochs,\n",
    "            steps_per_epoch=num_steps_per_epoch,\n",
    "            pct_start=config.warmup_prop\n",
    "        )\n",
    "        return scheduler, 'batch'\n",
    "\n",
    "    return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EgfrNoDescriptorRunner(dl.Runner):\n",
    "\n",
    "    def _handle_batch(self, batch):\n",
    "        smiles, _, _, labels = batch\n",
    "        out = self.model(input_ids=smiles)\n",
    "        self.batch_metrics['loss'] = \\\n",
    "          torch.nn.functional.binary_cross_entropy_with_logits(out.logits, labels.float().unsqueeze(-1))\n",
    "        self.input = {'targets': labels}\n",
    "        self.output = {'logits': out.logits}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cI5FoiV3rf2S",
    "outputId": "2a646037-8bce-4185-a53e-5ee932b053bb"
   },
   "outputs": [],
   "source": [
    "def experiment(train, valid, config, experiment_name, fold_idx):\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(config.tokenizer_path)\n",
    "    PAD_TOKEN_ID = tokenizer.pad_token_id\n",
    "\n",
    "    model_config = RobertaConfig(\n",
    "        vocab_size=tokenizer.vocab_size,\n",
    "        hidden_size=config.hidden_size,\n",
    "        num_hidden_layers=config.num_hidden_layers,\n",
    "        num_attention_heads=config.num_attention_heads,\n",
    "        intermediate_size=config.intermediate_size,\n",
    "        hidden_dropout_prob=config.hidden_dropout_prob,\n",
    "        attention_probs_dropout_prob=config.attention_probs_dropout_prob,\n",
    "        pad_token_id=PAD_TOKEN_ID,\n",
    "        num_labels=1\n",
    "    )\n",
    "    model = RobertaForSequenceClassification(config=model_config)\n",
    "\n",
    "    train_dataset = SequenceEGFRDataset(train, tokenizer)\n",
    "    valid_dataset = SequenceEGFRDataset(valid, tokenizer)\n",
    "\n",
    "    loaders = {\n",
    "        'train': train_dataset.make_loader(batch_size=config.batch_size, shuffle=True),\n",
    "        'valid': valid_dataset.make_loader(batch_size=config.batch_size)\n",
    "    }\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "    callbacks = [\n",
    "        dl.OptimizerCallback(accumulation_steps=config.accumulation_steps),\n",
    "        dl.EarlyStoppingCallback(patience=config.patience),\n",
    "        dl.WandbLogger(\n",
    "            project='egfr-project',\n",
    "            entity='dimaorekhov',\n",
    "            group=f\"{EXPERIMENT_NAME}_CV\",\n",
    "            name=f\"{EXPERIMENT_NAME}_fold_{fold_idx}\",\n",
    "            config=config.__dict__\n",
    "        ),\n",
    "        dl.AUCCallback(activation='Sigmoid')\n",
    "    ]\n",
    "\n",
    "    scheduler, mode = init_scheduler(optimizer, len(loaders['train']), config)\n",
    "    if scheduler is not None:\n",
    "        callbacks.append(dl.SchedulerCallback(mode=mode))\n",
    "\n",
    "    Path(config.logdir).mkdir(exist_ok=True)\n",
    "\n",
    "    runner = EgfrNoDescriptorRunner(device=DEVICE)\n",
    "    runner.train(\n",
    "        model=model,\n",
    "        loaders=loaders,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,        \n",
    "        num_epochs=config.num_epochs,\n",
    "        verbose=True,\n",
    "        logdir=config.logdir,\n",
    "        callbacks=callbacks,\n",
    "        check=True\n",
    "    )\n",
    "\n",
    "    model.to(torch.device(\"cpu\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (train, valid) in enumerate(train_cross_validation_split(DATA_PATH.as_posix())):\n",
    "    experiment(train, valid, config, EXPERIMENT_NAME, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "transformer-baseline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0a851a68408144c591138e2a356d1c5f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1456a5741e574d5f962b29b09c5f3c03": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2d1a199113614a339e4f4636171cb2de": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0a851a68408144c591138e2a356d1c5f",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4a135cde6d25454a93b25e05e8c02bfd",
      "value": 1
     }
    },
    "375cb9434b054352bba90a891f7d253e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f0e4b2b4a1594cccb10ecb6eca9b5838",
      "placeholder": "​",
      "style": "IPY_MODEL_1456a5741e574d5f962b29b09c5f3c03",
      "value": " 0.79MB of 0.79MB uploaded (0.00MB deduped)\r"
     }
    },
    "4a135cde6d25454a93b25e05e8c02bfd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b2bc5bc70f4542548dc70bc42f313a7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_375cb9434b054352bba90a891f7d253e",
       "IPY_MODEL_2d1a199113614a339e4f4636171cb2de"
      ],
      "layout": "IPY_MODEL_d42f5a9157f442dc905bd7641efdec24"
     }
    },
    "d42f5a9157f442dc905bd7641efdec24": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f0e4b2b4a1594cccb10ecb6eca9b5838": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
